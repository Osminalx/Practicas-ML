version()
instal.packages("lenguageserver")
install.packages("lenguageserver")
q()
q()
install.packages("Ecdat")
install.packages("RCurl")
#cargan las librerias de clusters
# para visualizar resultados de análisis de clusters
library(factoextra)
data<-USArrests
#eliminar registros con valores ausentes
data<-na.omit(data)
#Identificar los datos
head(data)
ue las variables tengan el mismo peso en el análisis de
clustering.
data<- scale.default(data)
data<- scale.default(data)
#get_dist: fpara calcular una matriz de distancia entre las filas de una matriz de datos.
distance <- get_dist(data)
#La medida de distancia predeterminada es la distancia euclidiana
d <- dist(data, method = "euclidean")
# Agrupación jerárquica mediante vinculación completa
hc1 <- hclust(d, method = "complete" )
# Visualizar el dendrograma obtenido.
plot(hc1, cex = 0.6, hang = -1)
# Calcular con Agnes
hc2 <- agnes(data, method = "complete")
d <- dist(data, method = "euclidean")
# Agrupación jerárquica mediante vinculación completa
hc1 <- hclust(d, method = "complete" )
# Visualizar el dendrograma obtenido.
plot(hc1, cex = 0.6, hang = -1)
# Calcular con Agnes
hc2 <- agnes(data, method = "complete")
#análisis de agrupamiento jerárquico: average, single, complete y ward.
m <- c("average", "single", "complete", "ward")
hc2$ac
hc2 <- agnes(data, method = "complete")
m <- c("average", "single", "complete", "ward")
names(m)<-c("average","single", "complete", "ward" )
#función para calcular el coeficiente aglomerativo (agnes() leyendo el valor de $ac)
#calcula el coeficiente aglomerativo para cada método de vinculación.
ac <- function(x){ agnes(data,method = x)$ac}
#calcular el coeficiente de aglomeración para cada método de vinculación de
agrupaciones
#cargan las librerias de clusters
# para visualizar resultados de análisis de clusters
library(factoextra)
library(gridExtra)
#Set de Datos
data("USArrests")
head(USArrests,10)
#calcular la varianza de cada variable
apply(USArrests,2,var)
#Crear un nuevo marco de datos con variables centradas
scaled_df <- apply(USArrests,2,scale)
head(scaled_df)
#Calcular valores propios y vectores propios
arrests.cov <-cov(scaled_df)
arrests.eigen <- eigen(arrests.cov)
str(arrests.eigen)
#Tomar los primeros conjuntos
(phi <- arrests.eigen$vectors[,1:2])
phi<-phi
#El conjunto de cargas para el primer componente
row.names(phi)<- c("murder","Assault","UbanPop","Rape")
colnames(phi)<- c("PC1","PC2")
phi
#Calcular puntuaciones
PC1 <- as.matrix(scaled_df) %%phi[,1]
PC2 <- as.matrix(scaled_df) %%phi[,2]
#Crear marco de datos con puntuaciones de componentes
PC <- data.frame(State= row.names(USArrests),PC1,PC2)
head(PC)
#Plot
ggplot(PC,aes(PC1,PC2))+
modelr::geom_ref_line(h=0)+
modelr::geom_ref_line(v=0)+
geom_text(aes(label = State), size=3)+
xlab("Primer componente principal")+
ylab("Segundo componente Principal")+
ggtitle("Primeros dos componentes primcipales de USArrests Date")
library(ggplot2)
library(gridExtra)
library(ggplot2)
#Set de Datos
data("USArrests")
head(USArrests,10)
#calcular la varianza de cada variable
apply(USArrests,2,var)
#Crear un nuevo marco de datos con variables centradas
scaled_df <- apply(USArrests,2,scale)
head(scaled_df)
#Calcular valores propios y vectores propios
arrests.cov <-cov(scaled_df)
arrests.eigen <- eigen(arrests.cov)
str(arrests.eigen)
#Tomar los primeros conjuntos
(phi <- arrests.eigen$vectors[,1:2])
phi<-phi
#El conjunto de cargas para el primer componente
row.names(phi)<- c("murder","Assault","UbanPop","Rape")
colnames(phi)<- c("PC1","PC2")
phi
#Calcular puntuaciones
PC1 <- as.matrix(scaled_df) %%phi[,1]
PC2 <- as.matrix(scaled_df) %%phi[,2]
#Crear marco de datos con puntuaciones de componentes
PC <- data.frame(State= row.names(USArrests),PC1,PC2)
head(PC)
#Plot
ggplot(PC,aes(PC1,PC2))+
modelr::geom_ref_line(h=0)+
modelr::geom_ref_line(v=0)+
geom_text(aes(label = State), size=3)+
xlab("Primer componente principal")+
ylab("Segundo componente Principal")+
ggtitle("Primeros dos componentes primcipales de USArrests Date")
rlang::last_trace()
setwd("~/Documentos/5to semestre/Machine learning/Practica redes neuronales")
library(caret)
library(neuralnet)
#librerias
library(caret)
library(neuralnet)
#librerias
library(caret)
library(neuralnet)
#data
data(iris)
# Verificar las primeras filas del conjunto de datos
head(iris)
#librerias
library(caret)
library(neuralnet)
#data
data(iris)
# Verificar las primeras filas del conjunto de datos
head(iris)
# Dividir el conjunto de datos en entrenamiento y prueba
set.seed(123)
indices_entrenamiento <- sample(1:nrow(iris), 0.7 * nrow(iris))
datos_entrenamiento <- iris[indices_entrenamiento, ]
datos_prueba <- iris[-indices_entrenamiento, ]
# Crear la fórmula para la red neuronal
formula <- as.formula("Species ~ Sepal.Length + Sepal.Width + Petal.Length +
Petal.Width")
# Crear y entrenar la red neuronal
modelo <- neuralnet(
formula,
data = datos_entrenamiento,
hidden = c(5, 3), # Número de neuronas en cada capa oculta
linear.output = FALSE # Especifica que la salida no es lineal (para clasificación)
)
# Visualizar la arquitectura de la red neuronal
plot(modelo)
# Hacer predicciones en el conjunto de prueba
predicciones <- predict(modelo, datos_prueba)
# Obtener el índice de la clase con la probabilidad más alta para cada fila
clases_predichas_indices <- max.col(predicciones)
# Convertir los índices a nombres de clases
clases_predichas <- factor(levels(datos_prueba$Species)[clases_predichas_indices],
levels = levels(datos_prueba$Species))
# Comparar las predicciones con las etiquetas reales
resultados <- data.frame(
Real = datos_prueba$Species,
Predicho = clases_predichas
)
# Imprimir los resultados
print(resultados)
# Crear la matriz de confusión
matriz_confusion <- confusionMatrix(resultados$Predicho, resultados$Real)
# Imprimir la matriz de confusión
print(matriz_confusion)
#librerias
library(caret)
library(neuralnet)
#data
data(iris)
# Verificar las primeras filas del conjunto de datos
head(iris)
# Dividir el conjunto de datos en entrenamiento y prueba
set.seed(123)
indices_entrenamiento <- sample(1:nrow(iris), 0.7 * nrow(iris))
datos_entrenamiento <- iris[indices_entrenamiento, ]
datos_prueba <- iris[-indices_entrenamiento, ]
# Crear la fórmula para la red neuronal
formula <- as.formula("Species ~ Sepal.Length + Sepal.Width + Petal.Length +
Petal.Width")
# Crear y entrenar la red neuronal
modelo <- neuralnet(
formula,
data = datos_entrenamiento,
hidden = c(5, 3), # Número de neuronas en cada capa oculta
linear.output = FALSE # Especifica que la salida no es lineal (para clasificación)
)
# Visualizar la arquitectura de la red neuronal
plot(modelo)
# Hacer predicciones en el conjunto de prueba
predicciones <- predict(modelo, datos_prueba)
# Obtener el índice de la clase con la probabilidad más alta para cada fila
clases_predichas_indices <- max.col(predicciones)
# Convertir los índices a nombres de clases
clases_predichas <- factor(levels(datos_prueba$Species)[clases_predichas_indices],
levels = levels(datos_prueba$Species))
# Comparar las predicciones con las etiquetas reales
resultados <- data.frame(
Real = datos_prueba$Species,
Predicho = clases_predichas
)
# Imprimir los resultados
print(resultados)
# Crear la matriz de confusión
matriz_confusion <- confusionMatrix(resultados$Predicho, resultados$Real)
# Imprimir la matriz de confusión
print(matriz_confusion)
modelo2 <- neuralnet(
formula2,
data = datos_entrenamiento,
hidden = c(5, 3, 2), # Número de neuronas en cada capa oculta
act.fct = c("logistic", "tanh", "linear"),
linear.output = FALSE # Especifica que la salida no es lineal (para clasificación)
)
formula2 <- as.formula("Species ~ Sepal.Length + Sepal.Width + Petal.Length +
Petal.Width")
modelo2 <- neuralnet(
formula2,
data = datos_entrenamiento,
hidden = c(5, 3, 2), # Número de neuronas en cada capa oculta
act.fct = c("logistic", "tanh", "linear"),
linear.output = FALSE # Especifica que la salida no es lineal (para clasificación)
)
# Visualizar la arquitectura de la red neuronal
plot(modelo2)
# Hacer predicciones en el conjunto de prueba
predicciones2 <- predict(modelo2, datos_prueba)
# Obtener el índice de la clase con la probabilidad más alta para cada fila
clases_predichas_indices2 <- max.col(predicciones2)
# Convertir los índices a nombres de clases
clases_predichas2 <- factor(levels(datos_prueba$Species)[clases_predichas_indices2],
levels = levels(datos_prueba$Species))
# Comparar las predicciones con las etiquetas reales
resultados2 <- data.frame(
Real = datos_prueba$Species,
Predicho = clases_predichas2)
# Imprimir los resultados
print(resultados2)
# Crear la matriz de confusión
matriz_confusion2 <- confusionMatrix(resultados2$Predicho, resultados2$Real)
# Imprimir la matriz de confusión
print(matriz_confusion2)
# Crear y entrenar la red neuronal con la función de activación tanh
#Una capa oculta con 5 nodos y otra capa oculta de 3 nodos
modelo3 <- neuralnet(
formula2,
data = datos_entrenamiento,
hidden = c(5, 3), # Número de neuronas en cada capa oculta
act.fct = "tanh", # Especificar las funciones de activación
linear.output = FALSE # Especifica que la salida no es lineal (para clasificación)
)
# Visualizar la arquitectura de la red neuronal
plot(modelo3)
# Hacer predicciones en el conjunto de prueba
predicciones3 <- predict(modelo3, datos_prueba)
# Obtener el índice de la clase con la probabilidad más alta para cada fila
clases_predichas_indices3 <- max.col(predicciones3)
# Convertir los índices a nombres de clases
clases_predichas3<- factor(levels(datos_prueba$Species)[clases_predichas_indices3],
levels = levels(datos_prueba$Species))
# Comparar las predicciones con las etiquetas reales
resultados3 <- data.frame(
Real = datos_prueba$Species,
Predicho = clases_predichas3
)
# Imprimir los resultados
print(resultados3)
# Crear la matriz de confusión
matriz_confusion3 <- confusionMatrix(resultados3$Predicho, resultados3$Real)
# Imprimir la matriz de confusión
print(matriz_confusion3)
#librerias
library(caret)
library(neuralnet)
#data
data(iris)
# Verificar las primeras filas del conjunto de datos
head(iris)
# Dividir el conjunto de datos en entrenamiento y prueba
set.seed(123)
indices_entrenamiento <- sample(1:nrow(iris), 0.7 * nrow(iris))
datos_entrenamiento <- iris[indices_entrenamiento, ]
datos_prueba <- iris[-indices_entrenamiento, ]
# Crear la fórmula para la red neuronal
formula <- as.formula("Species ~ Sepal.Length + Sepal.Width + Petal.Length +
Petal.Width")
# Crear y entrenar la red neuronal
modelo <- neuralnet(
formula,
data = datos_entrenamiento,
hidden = c(5, 3), # Número de neuronas en cada capa oculta
linear.output = FALSE # Especifica que la salida no es lineal (para clasificación)
)
# Visualizar la arquitectura de la red neuronal
plot(modelo)
# Hacer predicciones en el conjunto de prueba
predicciones <- predict(modelo, datos_prueba)
# Obtener el índice de la clase con la probabilidad más alta para cada fila
clases_predichas_indices <- max.col(predicciones)
# Convertir los índices a nombres de clases
clases_predichas <- factor(levels(datos_prueba$Species)[clases_predichas_indices],
levels = levels(datos_prueba$Species))
# Comparar las predicciones con las etiquetas reales
resultados <- data.frame(
Real = datos_prueba$Species,
Predicho = clases_predichas
)
# Imprimir los resultados
print(resultados)
# Crear la matriz de confusión
matriz_confusion <- confusionMatrix(resultados$Predicho, resultados$Real)
# Imprimir la matriz de confusión
print(matriz_confusion)
# Crear y entrenar la red neuronal con diferentes funciones de activación tanh
#Esta red neuronal tiene tres capas: la capa de entrada,
#una capa oculta con función de activación logística ("logistic"),
#otra capa oculta con función de activación tangente hiperbólica ("tanh"),
#y otra capa oculta con función de activación lineal ("linear")
formula2 <- as.formula("Species ~ Sepal.Length + Sepal.Width + Petal.Length +
Petal.Width")
modelo2 <- neuralnet(
formula2,
data = datos_entrenamiento,
hidden = c(5, 3, 2), # Número de neuronas en cada capa oculta
act.fct = c("logistic", "tanh", "linear"),
linear.output = FALSE # Especifica que la salida no es lineal (para clasificación)
)
# Visualizar la arquitectura de la red neuronal
plot(modelo2)
#librerias
library(caret)
library(neuralnet)
#data
data(iris)
# Verificar las primeras filas del conjunto de datos
head(iris)
# Dividir el conjunto de datos en entrenamiento y prueba
set.seed(123)
indices_entrenamiento <- sample(1:nrow(iris), 0.7 * nrow(iris))
datos_entrenamiento <- iris[indices_entrenamiento, ]
datos_prueba <- iris[-indices_entrenamiento, ]
# Crear la fórmula para la red neuronal
formula <- as.formula("Species ~ Sepal.Length + Sepal.Width + Petal.Length +
Petal.Width")
# Crear y entrenar la red neuronal
modelo <- neuralnet(
formula,
data = datos_entrenamiento,
hidden = c(5, 3), # Número de neuronas en cada capa oculta
linear.output = FALSE # Especifica que la salida no es lineal (para clasificación)
)
# Visualizar la arquitectura de la red neuronal
plot(modelo)
predicciones <- predict(modelo, datos_prueba)
# Obtener el índice de la clase con la probabilidad más alta para cada fila
clases_predichas_indices <- max.col(predicciones)
# Convertir los índices a nombres de clases
clases_predichas <- factor(levels(datos_prueba$Species)[clases_predichas_indices],
levels = levels(datos_prueba$Species))
# Comparar las predicciones con las etiquetas reales
resultados <- data.frame(
Real = datos_prueba$Species,
Predicho = clases_predichas
)
# Imprimir los resultados
print(resultados)
# Crear la matriz de confusión
matriz_confusion <- confusionMatrix(resultados$Predicho, resultados$Real)
# Imprimir la matriz de confusión
print(matriz_confusion)
formula2 <- as.formula("Species ~ Sepal.Length + Sepal.Width + Petal.Length +
Petal.Width")
modelo2 <- neuralnet(
formula2,
data = datos_entrenamiento,
hidden = c(5, 3, 2), # Número de neuronas en cada capa oculta
act.fct = c("logistic", "tanh", "linear"),
linear.output = FALSE # Especifica que la salida no es lineal (para clasificación)
)
# Visualizar la arquitectura de la red neuronal
plot(modelo2)
# Hacer predicciones en el conjunto de prueba
predicciones2 <- predict(modelo2, datos_prueba)
# Obtener el índice de la clase con la probabilidad más alta para cada fila
clases_predichas_indices2 <- max.col(predicciones2)
# Convertir los índices a nombres de clases
clases_predichas2 <- factor(levels(datos_prueba$Species)[clases_predichas_indices2],
levels = levels(datos_prueba$Species))
# Comparar las predicciones con las etiquetas reales
resultados2 <- data.frame(
Real = datos_prueba$Species,
Predicho = clases_predichas2)
# Imprimir los resultados
print(resultados2)
# Crear la matriz de confusión
matriz_confusion2 <- confusionMatrix(resultados2$Predicho, resultados2$Real)
# Imprimir la matriz de confusión
print(matriz_confusion2)
modelo3 <- neuralnet(
formula2,
data = datos_entrenamiento,
hidden = c(5, 3), # Número de neuronas en cada capa oculta
act.fct = "tanh", # Especificar las funciones de activación
linear.output = FALSE # Especifica que la salida no es lineal (para clasificación)
)
# Visualizar la arquitectura de la red neuronal
plot(modelo3)
# Hacer predicciones en el conjunto de prueba
predicciones3 <- predict(modelo3, datos_prueba)
# Obtener el índice de la clase con la probabilidad más alta para cada fila
clases_predichas_indices3 <- max.col(predicciones3)
# Convertir los índices a nombres de clases
clases_predichas3<- factor(levels(datos_prueba$Species)[clases_predichas_indices3],
levels = levels(datos_prueba$Species))
# Comparar las predicciones con las etiquetas reales
resultados3 <- data.frame(
Real = datos_prueba$Species,
Predicho = clases_predichas3
)
# Imprimir los resultados
print(resultados3)
matriz_confusion3 <- confusionMatrix(resultados3$Predicho, resultados3$Real)
# Imprimir la matriz de confusión
print(matriz_confusion3)
